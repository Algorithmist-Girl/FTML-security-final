Building on the paper [Robust Textual Embedding against Word-level Adversarial Attacks (UAI 2022)](https://arxiv.org/abs/2202.13817).

Citation of the paper:
Yichen Yang, Xiaosen Wang, and Kun He. Robust textual
embedding against word-level adversarial attacks. In
Uncertainty in Artificial Intelligence, 2022


Please view their README for the setup to run the experiments along with the full list of commands for experiments: https://github.com/JHL-HUST/FTML
